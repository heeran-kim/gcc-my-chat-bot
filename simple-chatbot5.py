"""
This simple chatbot application allows users to upload a PDF file and extracts the text content from it,
and then splits the text into manageable chunks. The extracted text is then displayed on the web page
Users can input questions to perform similarity searches on the text.
It uses an LLM to generate comprehensive answers based on the extracted content. (NEW)

Libraries used:
- Streamlit: For creating the web interface.
- PyPDF2: For reading and extracting text from PDF files.
- LangChain: For splitting text into chunks.
- OpenAIEmbeddings: For generating embeddings from text chunks.
- FAISS: For storing embeddings in a vector store.
- LangChain QA Chain: For generating answers to user questions based on retrieved text chunks. (NEW)
- ChatOpenAI: For interacting with the OpenAI API to generate answers. (NEW)

Features:
- PDF File Upload: Users can upload a PDF file via the sidebar.
- Text Extraction: The app extracts text from each page of the PDF and displays it.
- User Prompt: If no file is uploaded, the app prompts the user to upload a file.
- Text Splitting: The extracted text is split into chunks using the RecursiveCharacterTextSplitter from LangChain.
    This is useful for processing large texts in smaller parts.
- Embeddings Generation: The text chunks are converted into embeddings using OpenAI's API.
- Vector Store: The embeddings are stored in a FAISS vector store for efficient similarity search.
- User Query Input: Allows the user to input a question, which is then matched against the text chunks to find relevant information.
- Similarity Search: The app performs a similarity search using FAISS and returns the most relevant text chunks based on the user's question.
- LLM Integration: Uses a language model from OpenAI to generate detailed answers to user queries based on the retrieved text chunks. (NEW)

Output:
- The extracted text chunks are displayed on the web page.
- A detailed answer to the user's question is generated by the LLM and displayed on the web page. (NEW)

This application can be a foundational step for building more complex text processing or chatbot applications based on PDF content.
"""
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain_community.chat_models import ChatOpenAI

import os

key = os.getenv("OPEN_API_KEY")

st.header("A simple chat bot based on one pdf file")

st.sidebar.header("Document")

file = st.sidebar.file_uploader("Input a PDF file", type='pdf')

text_splitter = RecursiveCharacterTextSplitter(
    separators = "\n",
    chunk_size = 1000,
    chunk_overlap = 150,
    length_function = len
)

if file is not None:
    pdf_reader = PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    chunks = text_splitter.split_text(text)
    st.write(chunks)
    embeddings = OpenAIEmbeddings(openai_api_key = key)
    vector_store = FAISS.from_texts(chunks, embeddings)

    question = st.text_input("Input your question")
    matches = vector_store.similarity_search(question)
    if question:
        # Initialise the language model using the OpenAI API key
        llm = ChatOpenAI(
            openai_api_key = key,
            temperature = 0, # The temperature is set to 0 for deterministic responses
            max_tokens = 1000, # max_tokens limits the number of tokens in the generated response
            model = "gpt-4o"
        )
        # Create a question-answering chain using the language model
        # The chain_type "stuff" is typically used for simple Q&A tasks
        chain = load_qa_chain(llm, chain_type = "stuff")
        # Run the Q&A chain with the retrieved text chunks and the user's question
        # input_documents contains the text chunks that matched the user's query
        # question is the user's input, which will be used to generate the answer
        answer = chain.run(input_documents = matches, question = question)
        st.write(answer)
else:
    st.write("Input a file...")
